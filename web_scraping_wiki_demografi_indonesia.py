# -*- coding: utf-8 -*-
"""Web Scraping: Wiki_Demografi_Indonesia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bpyF17fkqWIODkv6-NOM4fsOaSDqCa3I

#**Web Scraping**
Wikipedia: Demografi Indonesia
"""

#import library yang dibutuhkan

import pandas as pd
import requests
from bs4 import BeautifulSoup

url = 'https://id.wikipedia.org/wiki/Demografi_Indonesia'

#buatlah request ke website

site = requests.get(url).text
soup = BeautifulSoup(site, 'html.parser')

#menampilkan html code dari site
print(soup)

#ambil tabel dengan class=wikitable sortable

table = soup.find('table',{'class':'wikitable sortable'})
print(table)

#menemukan tag 'td' dari table yang sudah didefinisikan
#menemukan konten yang diharapkan

links = table.find_all('td')
print(links)

#mendefinisikan array kosong untuk setiap konten

nama = []
luas = []
pop10 = []
pop20 = []

#memasukkan data ke dalam list berdasarkan pola HTML
#merapikan isi data dengan .strip()

for i, link in enumerate(links): 
	if i in range(0, len(links), 4):
		nama.append(link.get_text().strip())
	if i in range(1, len(links), 4):
		luas.append(link.get_text().strip())
	if i in range(2, len(links), 4):
		pop10.append(link.get_text().strip())
	if i in range(3, len(links), 4):
		pop20.append(link.get_text().strip())
  
#enumerate digunaka untuk membentuk data memiliki urutan
#setiap konten data memiliki rentang 4 baris

#buatlah setiap list ke dalam suatu DataFrame 

data = {'Nama_Prov':nama, 'Luas':luas, 'Populasi 2010':pop10, 'Populasi 2020':pop20}
df = pd.DataFrame(data)

df.head()

#simpan ke dalam csv

df.to_csv('Indonesia_Demography_by_Province.csv', index=False, encoding='utf-8', quoting=1)